{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e33796",
   "metadata": {},
   "source": [
    "#### Competitor Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e27b5",
   "metadata": {},
   "source": [
    "Мы занимаемся динамическим ценообразованием и хотим, чтобы наша модель учитывала цены конкурентов. Пусть для каждого товара (sku) у нас имеется base_price – наша текущая цена. На каждый наш товар благодаря команде матчинга найдены 1, несколько или ни одной цен конкурентов – они записаны в колонке comp_price. Конкуренты имеют приоритет (колонка rank), причём в рангах могут быть пропуски (либо -1, если не найдено ни одной цены конкурента).\n",
    "\n",
    "Поскольку может быть найдено несколько цен конкурентов, их необходимо согласно какому-то правилу агрегировать. В колонке agg указан тип агрегации:\n",
    "\n",
    "1.\t'avg' – берем среднее\n",
    "\n",
    "2.\t'med' – медиану\n",
    "\n",
    "3.\t'min' – минимальную цену\n",
    "\n",
    "4.\t'max' – максимальную\n",
    "\n",
    "5.\t'rnk' – цену конкурента, имеющего наибольший приоритет (наименьший ранг)\n",
    "\n",
    "После агрегации мы записываем агрегированную цену конкурента в колонку comp_price.\n",
    "\n",
    "Осталось определиться, какую брать финальную цену new_price:\n",
    "\n",
    "•\tесли для товара цен конкурентов не найдено, оставляем старую цену\n",
    "\n",
    "•\tесли агрегированная цена конкурента отличается не более чем на ± 20% от старой цены, ставим её, иначе оставляем старую\n",
    "\n",
    "________________________________________\n",
    "> Описание решения\n",
    "\n",
    "Напишите функцию agg_comp_price, которая на вход принимает датафрейм, группирует его по полю sku, вариант группировки указан в поле agg (Для одинаковых sku, agg одинаковые).\n",
    "Решение должно быть отсортировано по sku, а индекс начинаться с 0 и быть последовательным.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eae2f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76e4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def agg_comp_price(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    aggs = {'avg':'mean', 'med':'median', 'min':lambda x: min(x), 'max':lambda x: max(x), 'rnk':None}\n",
    "    skus = X.sku.unique()\n",
    "    agg_price = []\n",
    "    for sku in skus:\n",
    "        agg_function = X[X['sku']==sku]['agg'].values[0]\n",
    "        if agg_function != 'rnk':\n",
    "            new = X[X['sku']==sku].groupby(['sku', 'agg'], as_index=False).agg(aggs[agg_function])['comp_price'].values[0]\n",
    "            agg_price.append(new)\n",
    "        else:\n",
    "            rank = min(X[X['sku']==sku]['rank'].values)\n",
    "            new = X[(X['sku']==sku)&(X['rank']==rank)]['comp_price'].values[0]\n",
    "            agg_price.append(new)\n",
    "    X = X.groupby(['sku', 'agg', 'base_price'], as_index=False).count()\n",
    "    X.drop('rank', axis=1, inplace=True)\n",
    "    X['comp_price']=agg_price\n",
    "    X['new_price']=np.where(np.abs(1-(X['base_price']/X['comp_price'])) > 0.2, \n",
    "                                 X['base_price'], X['comp_price'])\n",
    "    X['new_price']=np.where(np.isnan(X['new_price']), X['base_price'], X['new_price'])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "785200f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>agg</th>\n",
       "      <th>rank</th>\n",
       "      <th>base_price</th>\n",
       "      <th>comp_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>max</td>\n",
       "      <td>-1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>med</td>\n",
       "      <td>0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>med</td>\n",
       "      <td>1</td>\n",
       "      <td>17.7</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>avg</td>\n",
       "      <td>0</td>\n",
       "      <td>76.7</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>avg</td>\n",
       "      <td>1</td>\n",
       "      <td>76.7</td>\n",
       "      <td>73.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sku  agg  rank  base_price  comp_price\n",
       "0    0  max    -1        33.0         NaN\n",
       "1    1  med     0        17.7        16.4\n",
       "2    1  med     1        17.7        21.8\n",
       "3    2  avg     0        76.7        77.0\n",
       "4    2  avg     1        76.7        73.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('comp_price.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dd733ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>agg</th>\n",
       "      <th>base_price</th>\n",
       "      <th>comp_price</th>\n",
       "      <th>new_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>max</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>med</td>\n",
       "      <td>17.7</td>\n",
       "      <td>19.10</td>\n",
       "      <td>19.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>avg</td>\n",
       "      <td>76.7</td>\n",
       "      <td>75.45</td>\n",
       "      <td>75.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>rnk</td>\n",
       "      <td>39.7</td>\n",
       "      <td>37.40</td>\n",
       "      <td>37.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>max</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.40</td>\n",
       "      <td>22.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>max</td>\n",
       "      <td>84.8</td>\n",
       "      <td>106.00</td>\n",
       "      <td>84.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>min</td>\n",
       "      <td>73.6</td>\n",
       "      <td>31.70</td>\n",
       "      <td>73.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>med</td>\n",
       "      <td>58.6</td>\n",
       "      <td>71.30</td>\n",
       "      <td>71.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>rnk</td>\n",
       "      <td>35.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>rnk</td>\n",
       "      <td>87.0</td>\n",
       "      <td>88.20</td>\n",
       "      <td>88.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sku  agg  base_price  comp_price  new_price\n",
       "0    0  max        33.0         NaN      33.00\n",
       "1    1  med        17.7       19.10      19.10\n",
       "2    2  avg        76.7       75.45      75.45\n",
       "3    3  rnk        39.7       37.40      37.40\n",
       "4    4  max        18.0       22.40      22.40\n",
       "5    5  max        84.8      106.00      84.80\n",
       "6    6  min        73.6       31.70      73.60\n",
       "7    7  med        58.6       71.30      71.30\n",
       "8    8  rnk        35.2         NaN      35.20\n",
       "9    9  rnk        87.0       88.20      88.20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_comp_price(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7221dcf",
   "metadata": {},
   "source": [
    "#### Elasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2a75c2",
   "metadata": {},
   "source": [
    "Вам необходимо дописать функцию elasticity_df, которая принимает на вход датасет и возвращает эластичность для каждого SKU.\n",
    "________________________________________\n",
    "Чтобы подсчитать эластичность:\n",
    "\n",
    "1.\tДля каждого товара постройте линейную зависимость логарифма продаж от цены.\n",
    "\n",
    "2.\tВозьмите коэффициент детерминации линейной регрессии R2 как оценку эластичности для данного товара\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f79f373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "def elasticity_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "\n",
    "    df.sort_values('sku', inplace = True)\n",
    "    skus = df.sku.unique()\n",
    "    rsquared = []\n",
    "    for sku in skus:\n",
    "        df_part = df[df['sku']==sku]\n",
    "        model = smf.ols(formula = 'np.log(qty + 1) ~ price', data = df_part)\n",
    "        result = model.fit()\n",
    "        if result.rsquared == -np.inf:\n",
    "            rsquared.append(0)\n",
    "        else:\n",
    "            rsquared.append(result.rsquared)\n",
    "    new_df = df.groupby('sku', as_index = False).count()\n",
    "    new_df.drop(['dates', 'price', 'qty'], axis = 1, inplace = True)\n",
    "    new_df['elasticity'] = rsquared             \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d64df92d",
   "metadata": {},
   "outputs": [
    {
     "ename": "PatsyError",
     "evalue": "Error evaluating factor: NameError: name 'qty' is not defined\n    np.log(qty + 1) ~ price\n    ^^^^^^^^^^^^^^^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\patsy\\compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[1;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\patsy\\eval.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"eval\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         return eval(code, {}, VarLookupDict([inner_namespace]\n\u001b[0m\u001b[0;32m    166\u001b[0m                                             + self._namespaces))\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'qty' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4916\\1474135999.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0melasticity_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4916\\3389883357.py\u001b[0m in \u001b[0;36melasticity_df\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msku\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mdf_part\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sku'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0msku\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformula\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'np.log(qty + 1) ~ price'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_part\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsquared\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m         tmp = handle_formula_data(data, None, formula, depth=eval_env,\n\u001b[0m\u001b[0;32m    201\u001b[0m                                   missing=missing)\n\u001b[0;32m    202\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesign_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\formula\\formulatools.py\u001b[0m in \u001b[0;36mhandle_formula_data\u001b[1;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_using_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n\u001b[0m\u001b[0;32m     64\u001b[0m                                NA_action=na_action)\n\u001b[0;32m     65\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36mdmatrices\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    307\u001b[0m     \"\"\"\n\u001b[0;32m    308\u001b[0m     \u001b[0meval_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n\u001b[0m\u001b[0;32m    310\u001b[0m                                       NA_action, return_type)\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36m_do_highlevel_design\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[0m\u001b[0;32m    165\u001b[0m                                       NA_action)\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdesign_infos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36m_try_incr_builders\u001b[1;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformula_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelDesc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         return design_matrix_builders([formula_like.lhs_termlist,\n\u001b[0m\u001b[0;32m     67\u001b[0m                                        formula_like.rhs_termlist],\n\u001b[0;32m     68\u001b[0m                                       \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\patsy\\build.py\u001b[0m in \u001b[0;36mdesign_matrix_builders\u001b[1;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[1;31m# on some data to find out what type of data they return.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m     (num_column_counts,\n\u001b[1;32m--> 693\u001b[1;33m      \u001b[0mcat_levels_contrasts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_examine_factor_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_factors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m                                                    \u001b[0mfactor_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m                                                    \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\patsy\\build.py\u001b[0m in \u001b[0;36m_examine_factor_types\u001b[1;34m(factors, factor_states, data_iter_maker, NA_action)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamine_needed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactor_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfactor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcat_sniffers\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mguess_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcat_sniffers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\patsy\\eval.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, memorize_state, data)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemorize_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m         return self._eval(memorize_state[\"eval_code\"],\n\u001b[0m\u001b[0;32m    565\u001b[0m                           \u001b[0mmemorize_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m                           data)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\patsy\\eval.py\u001b[0m in \u001b[0;36m_eval\u001b[1;34m(self, code, memorize_state, data)\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemorize_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[0minner_namespace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVarLookupDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemorize_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"transforms\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         return call_and_wrap_exc(\"Error evaluating factor\",\n\u001b[0m\u001b[0;32m    548\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m                                  \u001b[0mmemorize_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eval_env\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\patsy\\compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[1;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m                                  origin)\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# Use 'exec' to hide this syntax from the Python 2 parser:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"raise new_exc from e\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# In python 2, we just let the original exception escape -- better\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\patsy\\compat.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mPatsyError\u001b[0m: Error evaluating factor: NameError: name 'qty' is not defined\n    np.log(qty + 1) ~ price\n    ^^^^^^^^^^^^^^^"
     ]
    }
   ],
   "source": [
    "elasticity_df(df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc3ec04",
   "metadata": {},
   "source": [
    "#### Similar Items Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a62cc67",
   "metadata": {},
   "source": [
    "В данной задаче мы сконцентрируемся на ценах на похожих товаров. \n",
    "\n",
    "Вам даны два словаря: \n",
    "\n",
    "1.\tembeddings - словарь с эмбеддингами, в качестве ключей выступают идентификаторы товаров. Гарантируется, что все вектора одной длины.\n",
    "\n",
    "2.\tprices - словарь с ценами, в качестве ключей выступают идентификаторы товаров. В нем нет пустых значений.\n",
    "\n",
    "Вам нужно заполнить класс SimilarItems с 3 вспомогательными методами и основную функцию transform - она возвращает новую цену для каждого товара.\n",
    "\n",
    "Функция distances\n",
    "________________________________________\n",
    "Функция считает попарные расстояния между всеми эмбеддингами, возвращая словарь расстояний.\n",
    "\n",
    "Функция knn\n",
    "________________________________________\n",
    "На вход функция принимает результат работы функции distance, и параметр top - кол-во ближайших соседей. Она выдает словарь с парами item_id - список top ближайших товаров.\n",
    "\n",
    "Функция knn_price\n",
    "________________________________________\n",
    "На вход функция принимает результат работы функции knn и словарь price с ценами для каждого товара. На выходе выдавая средневзвешенную цену top ближайших соседей. Округлите новую цену до двух знаков после запятой.\n",
    "\n",
    "Функция transform\n",
    "________________________________________\n",
    "Преобразует исходный словарь эмбеддингов в словарь с новыми ценами для всех товаров.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afef2d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Dict, Tuple, List\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from itertools import combinations\n",
    "\n",
    "class SimilarItems(BaseModel):\n",
    "\n",
    "    @staticmethod\n",
    "    def distances(\n",
    "        embeddings: Dict[int, np.ndarray]\n",
    "    ) -> Dict[Tuple[int, int], float]:\n",
    "        \"\"\"Calculate pairwise distances between each item\n",
    "        in embedding. We use cosine metric.\n",
    "\n",
    "        Args:\n",
    "            embeddings (Dict[int, np.ndarray]): Items embeddings\n",
    "\n",
    "        Returns:\n",
    "            Dict[Tuple[int, int], float]: Pairwise distances dict\n",
    "            Keys are in form of (i, j) - pairs of item_ids stored\n",
    "            in compact way\n",
    "        \"\"\"\n",
    "        pair_dists = {}\n",
    "        keys = combinations(embeddings.keys(), r=2)\n",
    "        for comb in keys:\n",
    "            A = embeddings[comb[0]]\n",
    "            B = embeddings[comb[1]]\n",
    "            cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "            pair_dists[comb] = cosine            \n",
    "        return pair_dists\n",
    "    \n",
    "    @staticmethod\n",
    "    def knn(\n",
    "        dist: Dict[Tuple[int, int], float], top: int\n",
    "    ) -> Dict[int, List[Tuple[int, float]]]:\n",
    "        \"\"\"Return closest neighbors for each item.\n",
    "\n",
    "        Args:\n",
    "            dist (Dict[Tuple[int, int], float]): <distances> method output\n",
    "            top (int): Number of top neighbors to consider.\n",
    "\n",
    "        Returns:\n",
    "            Dict[int, List[Tuple[int, float]]]: Dict with top closer neighbors\n",
    "            for each item.\n",
    "        \"\"\"\n",
    "        dist_dict = {}\n",
    "\n",
    "        for key, value in dist.items():\n",
    "            dist_dict.setdefault(key[0], [])    \n",
    "            dist_dict[key[0]].append((key[1], value))\n",
    "            dist_dict.setdefault(key[1], [])\n",
    "            val = (key[0], value)\n",
    "            if val not in dist_dict[key[1]]:\n",
    "                dist_dict[key[1]].append(val)\n",
    "                \n",
    "        knn_dict = {}\n",
    "        for key, value in dist_dict.items():\n",
    "            knn_dict[key] = sorted(value, key=lambda x: x[1], reverse=True)[:top]\n",
    "        return knn_dict    \n",
    "    \n",
    "    @staticmethod\n",
    "    def knn_price(\n",
    "        knn_dict: Dict[int, List[Tuple[int, float]]],\n",
    "        prices: Dict[int, float],\n",
    "    ) -> Dict[int, float]:\n",
    "        \"\"\"Calculate weighted average prices for each item.\n",
    "\n",
    "        Args:\n",
    "            knn_dict (Dict[int, List[Tuple[int, float]]]): <knn> method output.\n",
    "            prices (Dict[int, float]): Price dict for each item.\n",
    "\n",
    "        Returns:\n",
    "            Dict[int, float]: New prices dict, rounded to 2 decimal places.\n",
    "        \"\"\"\n",
    "        knn_price_dict = {}\n",
    "\n",
    "        for key, value in knn_dict.items():\n",
    "            price = 0\n",
    "            weight = 0\n",
    "            for item in value:\n",
    "                price += prices[item[0]]*item[1]\n",
    "                weight += item[1]\n",
    "            price /= weight\n",
    "            knn_price_dict[key]=round(price, 2)\n",
    "            \n",
    "        return knn_price_dict \n",
    "    \n",
    "    @staticmethod\n",
    "    def transform(\n",
    "        embeddings: Dict[int, np.ndarray],\n",
    "        prices: Dict[int, float],\n",
    "        top: int,\n",
    "    ) -> Dict[int, float]:\n",
    "        \"\"\"Transforming input embeddings into a dictionary\n",
    "        with weighted average prices for each item.\n",
    "\n",
    "        Args:\n",
    "            embeddings (Dict[int, np.ndarray]): Items embeddings\n",
    "            prices (Dict[int, float]): Price dict for each item\n",
    "            top (int): Number of top neighbors to consider\n",
    "\n",
    "        Returns:\n",
    "            Dict[int, float]: Dict with weighted average prices for each item\n",
    "        \"\"\"\n",
    "        dist = SimilarItems.distances(embeddings)\n",
    "        knn_dict = SimilarItems.knn(dist, top)\n",
    "        knn_price_dict = SimilarItems.knn_price(knn_dict, prices)\n",
    "        return knn_price_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3434cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {\n",
    "    1: np.array([-26.57, -76.61, 81.61, -9.11, 74.8, 54.23, 32.56, -22.62, -72.44, -82.78]),\n",
    "    2: np.array([-55.98, 82.87, 86.07, 18.71, -18.66, -46.74, -68.18, 60.29, 98.92, -78.95]),\n",
    "    3: np.array([-27.97, 25.39, -96.85, 3.51, 95.57, -27.48, -80.27, 8.39, 89.96, -36.68]),\n",
    "    4: np.array([-37.0, -49.39, 43.3, 73.36, 29.98, -56.44, -15.91, -56.46, 24.54, 12.43]),\n",
    "    5: np.array([-22.71, 4.47, -65.42, 10.11, 98.34, 17.96, -10.77, 2.5, -26.55, 69.16]),\n",
    "}\n",
    "\n",
    "\n",
    "prices = {\n",
    "    1: 100.5,\n",
    "    2: 12.2,\n",
    "    3: 60.0,\n",
    "    4: 11.1,\n",
    "    5: 245.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02202c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = SimilarItems()\n",
    "sim.transform(embeddings, prices, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878bbcd8",
   "metadata": {},
   "source": [
    "#### nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a9031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Gaine\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cumulative_gain(relevance: List[float], k: int) -> float:\n",
    "    \"\"\"Score is cumulative gain at k (CG@k)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    relevance:  `List[float]`\n",
    "        Relevance labels (Ranks)\n",
    "    k : `int`\n",
    "        Number of elements to be counted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "    \"\"\"\n",
    "    #top_relevance = sorted(relevance, reverse=True)\n",
    "    score = np.sum(relevance[:k])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance = [0.99, 0.94, 0.88, 0.74, 0.71, 0.68]\n",
    "k = 5\n",
    "print(cumulative_gain(relevance, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def discounted_cumulative_gain(relevance: List[float], k: int, method: str = \"standard\") -> float:\n",
    "    \"\"\"Discounted Cumulative Gain\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    relevance : `List[float]`\n",
    "        Video relevance list\n",
    "    k : `int`\n",
    "        Count relevance to compute\n",
    "    method : `str`, optional\n",
    "        Metric implementation method, takes the values \\\n",
    "            `standard` and `industry`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : `float`\n",
    "        Metric score\n",
    "    \"\"\"    \n",
    "    score = 0\n",
    "    if method == \"industry\":\n",
    "        for i, v in enumerate(relevance[:k], 1):\n",
    "            score += (2*v-1)/np.log2(i+1)\n",
    "            return score\n",
    "    for i, v in enumerate(relevance[:k], 1):\n",
    "        score += v/np.log2(i+1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8899758",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance = [0.99, 0.94, 0.88, 0.74, 0.71, 0.68]\n",
    "k = 5\n",
    "method = 'standard'\n",
    "print(discounted_cumulative_gain(relevance, k, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2cf240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalized_dcg(relevance: List[float], k: int, method: str = \"standard\") -> float:\n",
    "    \"\"\"Normalized Discounted Cumulative Gain.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    relevance : `List[float]`\n",
    "        Video relevance list\n",
    "    k : `int`\n",
    "        Count relevance to compute\n",
    "    method : `str`, optional\n",
    "        Metric implementation method,\n",
    "        takes the values `standard` and `industry`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : `float`\n",
    "        Metric score\n",
    "    \"\"\"\n",
    "    dcg = 0\n",
    "    idcg = 0\n",
    "    if method == \"industry\":\n",
    "        for i, v in enumerate(relevance[:k], 1):\n",
    "            dcg += (2*v-1)/np.log2(i+1)\n",
    "            \n",
    "        for i, v in enumerate(sorted(relevance[:k], reverse = True), 1):\n",
    "            idcg += (2*v-1)/np.log2(i+1)\n",
    "\n",
    "    else:   \n",
    "        for i, v in enumerate(relevance[:k], 1):\n",
    "            dcg += v/np.log2(i+1)  \n",
    "\n",
    "        for i, v in enumerate(sorted(relevance[:k], reverse = True), 1):\n",
    "            idcg += v/np.log2(i+1)\n",
    "    score = dcg/idcg\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af66c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance = [0.99, 0.94, 0.74, 0.88, 0.71, 0.68]\n",
    "k = 5 \n",
    "method = 'standard'\n",
    "print(normalized_dcg(relevance, k, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7af5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def avg_ndcg(list_relevances: List[List[float]], k: int, method: str = 'standard') -> float:\n",
    "    \"\"\"avarage nDCG\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    list_relevances : `List[List[float]]`\n",
    "        Video relevance matrix for various queries\n",
    "    k : `int`\n",
    "        Count relevance to compute\n",
    "    method : `str`, optional\n",
    "        Metric implementation method, takes the values\\\n",
    "             `standard` and `industry`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : `float`\n",
    "        Metric score\n",
    "    \"\"\"\n",
    "\n",
    "    score = np.mean(list(map(lambda x: (normalized_dcg(x, k, method)), list_relevances)))\n",
    "    return score\n",
    "\n",
    "list_relevances = [\n",
    "        [0.99, 0.94, 0.88, 0.89, 0.72, 0.65],\n",
    "        [0.99, 0.92, 0.93, 0.74, 0.61, 0.68], \n",
    "        [0.99, 0.96, 0.81, 0.73, 0.76, 0.69]\n",
    "    ]  \n",
    "k = 5\n",
    "method = 'standard'\n",
    "print(round(avg_ndcg(list_relevances, k, method), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d7e7c",
   "metadata": {},
   "source": [
    "#### Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f4bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import delayed\n",
    "from joblib import Parallel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def text_processing(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"https?://[^,\\s]+,?\", \"\", text)\n",
    "    text = re.sub(r\"@[^,\\s]+,?\", \"\", text)\n",
    "\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    transform_text = text.translate(str.maketrans(\"\", \"\", punctuation))\n",
    "    transform_text = re.sub(\" +\", \" \", transform_text)\n",
    "\n",
    "    text_tokens = word_tokenize(transform_text)\n",
    "\n",
    "    lemma_text = [\n",
    "        lemmatizer.lemmatize(word.lower()) for word in text_tokens\n",
    "        ]\n",
    "    \n",
    "    cleaned_text = \" \".join(\n",
    "            [str(word) for word in lemma_text if word not in stop_words]\n",
    "        )\n",
    "    return cleaned_text\n",
    "    \n",
    "\n",
    "def clear_data(source_path: str, target_path: str, n_jobs: int):\n",
    "    \"\"\"Parallel process dataframe\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    source_path : str\n",
    "        Path to load dataframe from\n",
    "\n",
    "    target_path : str\n",
    "        Path to save dataframe to\n",
    "\n",
    "    n_jobs : int\n",
    "        Count of job to process\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.read_parquet(source_path)\n",
    "    data = data.copy().dropna().reset_index(drop=True)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    cleaned_text_list = Parallel(\n",
    "        n_jobs=n_jobs, backend=\"multiprocessing\", verbose=5 * n_jobs\n",
    "    )(delayed(text_processing)(text) for text in data[\"text\"])\n",
    "    data[\"cleaned_text\"] = cleaned_text_list\n",
    "    data.to_parquet(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27760349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
